{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d861578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12eb78a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "(2, 2)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([[1.0, 2.0], \n",
    "                 [3.0, 4.0]])\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eb5cd",
   "metadata": {},
   "source": [
    "The most important attributes of a tf.Tensor are its shape, and dtype.\n",
    "- Tensor.shape\n",
    "- Tensor.dtype\n",
    "\n",
    "Tensorflow implements standard mathematical operations on tensors, as well as operations specified for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191cd4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 4.],\n",
       "       [6., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X + X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce4901",
   "metadata": {},
   "source": [
    "##   TensorFlow 中 tensor 的转置（tf.transpose）逻辑说明：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1134ef",
   "metadata": {},
   "source": [
    "### TensorFlow 中 tensor 的转置（tf.transpose）逻辑说明：\n",
    "\n",
    "1. perm 的含义：perm 是一个长度为 n 的整数列表，表示输出的第 k 个维度来自输入的第 perm[k] 个维度。\n",
    "   - 因此输出张量 y 的形状满足：y.shape[k] = x.shape[perm[k]]。\n",
    "   - 默认情况下，perm 会被设置为 [n-1, n-2, ..., 0]，也就是将维度反转（对 2D 就是常规矩阵转置）。\n",
    "\n",
    "2. 索引映射（更直观）：\n",
    "   - 如果 y = tf.transpose(x, perm)，则\n",
    "     y[i0, i1, ..., i{n-1}] = x[i_{perm[0]}, i_{perm[1]}, ..., i_{perm[n-1]}]。\n",
    "   - 例如：对于 2D（矩阵），perm=[1,0]，有 y[i,j] = x[j,i]；\n",
    "     对于 3D，perm=[1,0,2]，有 y[a,b,c] = x[b,a,c]（即交换第 0、1 两个维度）。\n",
    "\n",
    "3. conjugate 参数（仅对复数类型有效）：\n",
    "   - 如果 x.dtype 是 complex64 或 complex128，且调用 tf.transpose(x, conjugate=True)，\n",
    "     那么在转置的同时还会对数值做共轭（相当于复共轭转置）。\n",
    "\n",
    "4. 使用建议与注意事项：\n",
    "   - 对于高维张量，明确写出 perm 更易读也更可控；\n",
    "   - 如果只想交换两个维度，可用 perm 指定对应位置交换；\n",
    "   - 转置通常不改变内存占用，但可能改变内存布局，影响后续操作性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be2e0a",
   "metadata": {},
   "source": [
    "## 详细演示 tf.transpose 元素转换过程\n",
    "\n",
    "### 核心原理：索引映射规则\n",
    "如果 `y = tf.transpose(x, perm)`，那么：\n",
    "**`y[i0, i1, ..., i_{n-1}] = x[i_{perm[0]}, i_{perm[1]}, ..., i_{perm[n-1]}]`**\n",
    "\n",
    "这意味着：\n",
    "- 输出张量 y 在位置 `[i0, i1, ..., i_{n-1}]` 的元素\n",
    "- 来自输入张量 x 在位置 `[i_{perm[0]}, i_{perm[1]}, ..., i_{perm[n-1]}]` 的元素\n",
    "\n",
    "下面我们用具体例子来演示这个转换过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b799f4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "示例1：2D矩阵转置 perm=[1,0]\n",
      "============================================================\n",
      "原始矩阵 A (shape: 2x3):\n",
      "[[10 20 30]\n",
      " [40 50 60]]\n",
      "\n",
      "转置后 A_t (shape: 3x2):\n",
      "[[10 40]\n",
      " [20 50]\n",
      " [30 60]]\n",
      "\n",
      "元素转换过程详解:\n",
      "根据规则：A_t[i,j] = A[j,i] (因为perm=[1,0])\n",
      "\n",
      "A_t[0,0] = A[0,0] = 10 (来自 A[0,0] = 10)\n",
      "A_t[0,1] = A[1,0] = 40 (来自 A[1,0] = 40)\n",
      "A_t[1,0] = A[0,1] = 20 (来自 A[0,1] = 20)\n",
      "A_t[1,1] = A[1,1] = 50 (来自 A[1,1] = 50)\n",
      "A_t[2,0] = A[0,2] = 30 (来自 A[0,2] = 30)\n",
      "A_t[2,1] = A[1,2] = 60 (来自 A[1,2] = 60)\n",
      "\n",
      "可视化转换过程:\n",
      "A[0,0]=10 → A_t[0,0]=10\n",
      "A[0,1]=20 → A_t[1,0]=20\n",
      "A[0,2]=30 → A_t[2,0]=30\n",
      "A[1,0]=40 → A_t[0,1]=40\n",
      "A[1,1]=50 → A_t[1,1]=50\n",
      "A[1,2]=60 → A_t[2,1]=60\n"
     ]
    }
   ],
   "source": [
    "# 示例1：2D矩阵转置 - 逐步演示元素转换\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"示例1：2D矩阵转置 perm=[1,0]\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 创建一个2x3的矩阵\n",
    "A = tf.constant([[10, 20, 30], \n",
    "                 [40, 50, 60]])\n",
    "print(\"原始矩阵 A (shape: 2x3):\")\n",
    "print(A.numpy())\n",
    "\n",
    "# 转置：perm=[1,0] 意味着新矩阵的维度0来自原矩阵的维度1，维度1来自原矩阵的维度0\n",
    "A_t = tf.transpose(A, perm=[1, 0])\n",
    "print(f\"\\n转置后 A_t (shape: 3x2):\")\n",
    "print(A_t.numpy())\n",
    "\n",
    "print(\"\\n元素转换过程详解:\")\n",
    "print(\"根据规则：A_t[i,j] = A[j,i] (因为perm=[1,0])\")\n",
    "print()\n",
    "\n",
    "# 逐个验证每个元素的转换\n",
    "for i in range(3):  # A_t的行\n",
    "    for j in range(2):  # A_t的列\n",
    "        print(f\"A_t[{i},{j}] = A[{j},{i}] = {A_t[i,j].numpy()} (来自 A[{j},{i}] = {A[j,i].numpy()})\")\n",
    "\n",
    "print(\"\\n可视化转换过程:\")\n",
    "print(\"A[0,0]=10 → A_t[0,0]=10\")\n",
    "print(\"A[0,1]=20 → A_t[1,0]=20\") \n",
    "print(\"A[0,2]=30 → A_t[2,0]=30\")\n",
    "print(\"A[1,0]=40 → A_t[0,1]=40\")\n",
    "print(\"A[1,1]=50 → A_t[1,1]=50\")\n",
    "print(\"A[1,2]=60 → A_t[2,1]=60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34f30c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "示例2：3D张量转置 perm=[2,1,0] - 完全反转维度\n",
      "============================================================\n",
      "原始3D张量 B (shape: 2x2x3):\n",
      "B[0,:,:] =\n",
      "[[100 101 102]\n",
      " [110 111 112]]\n",
      "B[1,:,:] =\n",
      "[[200 201 202]\n",
      " [210 211 212]]\n",
      "\n",
      "转置后 B_t (shape: 3x2x2):\n",
      "B_t[0,:,:] =\n",
      "[[100 200]\n",
      " [110 210]]\n",
      "B_t[1,:,:] =\n",
      "[[101 201]\n",
      " [111 211]]\n",
      "B_t[2,:,:] =\n",
      "[[102 202]\n",
      " [112 212]]\n",
      "\n",
      "元素转换规则：B_t[i,j,k] = B[k,j,i] (因为perm=[2,1,0])\n",
      "\n",
      "验证几个关键元素的转换:\n",
      "B_t[0,0,0] = 100 ← B[0,0,0] = 100\n",
      "B_t[0,1,1] = 210 ← B[1,1,0] = 210\n",
      "B_t[1,0,1] = 201 ← B[1,0,1] = 201\n",
      "B_t[2,1,0] = 112 ← B[0,1,2] = 112\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"示例2：3D张量转置 perm=[2,1,0] - 完全反转维度\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 创建一个2x2x3的3D张量\n",
    "B = tf.constant([[[100, 101, 102], \n",
    "                  [110, 111, 112]], \n",
    "                 [[200, 201, 202], \n",
    "                  [210, 211, 212]]])\n",
    "\n",
    "print(\"原始3D张量 B (shape: 2x2x3):\")\n",
    "print(\"B[0,:,:] =\")\n",
    "print(B[0,:,:].numpy())\n",
    "print(\"B[1,:,:] =\") \n",
    "print(B[1,:,:].numpy())\n",
    "\n",
    "# 转置：perm=[2,1,0] 意味着：\n",
    "# - 新张量的维度0来自原张量的维度2\n",
    "# - 新张量的维度1来自原张量的维度1  \n",
    "# - 新张量的维度2来自原张量的维度0\n",
    "B_t = tf.transpose(B, perm=[2, 1, 0])\n",
    "print(f\"\\n转置后 B_t (shape: 3x2x2):\")\n",
    "print(\"B_t[0,:,:] =\")\n",
    "print(B_t[0,:,:].numpy())\n",
    "print(\"B_t[1,:,:] =\")\n",
    "print(B_t[1,:,:].numpy()) \n",
    "print(\"B_t[2,:,:] =\")\n",
    "print(B_t[2,:,:].numpy())\n",
    "\n",
    "print(\"\\n元素转换规则：B_t[i,j,k] = B[k,j,i] (因为perm=[2,1,0])\")\n",
    "print(\"\\n验证几个关键元素的转换:\")\n",
    "\n",
    "# 选择几个具体位置验证\n",
    "test_positions = [(0,0,0), (0,1,1), (1,0,1), (2,1,0)]\n",
    "\n",
    "for i, j, k in test_positions:\n",
    "    original_val = B[k, j, i].numpy()  # 根据perm=[2,1,0]，B_t[i,j,k] = B[k,j,i]\n",
    "    transposed_val = B_t[i, j, k].numpy()\n",
    "    print(f\"B_t[{i},{j},{k}] = {transposed_val} ← B[{k},{j},{i}] = {original_val}\")\n",
    "    assert transposed_val == original_val, \"转换验证失败！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b18187d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "示例3：3D张量部分维度交换 perm=[1,0,2]\n",
      "============================================================\n",
      "原始3D张量 C (shape: 2x3x2):\n",
      "可以理解为2个3x2的矩阵:\n",
      "C[0,:,:] =\n",
      "[[100 101]\n",
      " [110 111]\n",
      " [120 121]]\n",
      "C[1,:,:] =\n",
      "[[200 201]\n",
      " [210 211]\n",
      " [220 221]]\n",
      "\n",
      "转置后 C_t (shape: 3x2x2):\n",
      "现在变成3个2x2的矩阵:\n",
      "C_t[0,:,:] =\n",
      "[[100 101]\n",
      " [200 201]]\n",
      "C_t[1,:,:] =\n",
      "[[110 111]\n",
      " [210 211]]\n",
      "C_t[2,:,:] =\n",
      "[[120 121]\n",
      " [220 221]]\n",
      "\n",
      "元素转换规则：C_t[i,j,k] = C[j,i,k] (因为perm=[1,0,2])\n",
      "详细转换过程:\n",
      "C_t[0,0,0] = 100 ← C[0,0,0] = 100\n",
      "C_t[0,0,1] = 101 ← C[0,0,1] = 101\n",
      "C_t[0,1,0] = 200 ← C[1,0,0] = 200\n",
      "C_t[0,1,1] = 201 ← C[1,0,1] = 201\n",
      "C_t[1,0,0] = 110 ← C[0,1,0] = 110\n",
      "C_t[1,0,1] = 111 ← C[0,1,1] = 111\n",
      "C_t[1,1,0] = 210 ← C[1,1,0] = 210\n",
      "C_t[1,1,1] = 211 ← C[1,1,1] = 211\n",
      "C_t[2,0,0] = 120 ← C[0,2,0] = 120\n",
      "C_t[2,0,1] = 121 ← C[0,2,1] = 121\n",
      "C_t[2,1,0] = 220 ← C[1,2,0] = 220\n",
      "C_t[2,1,1] = 221 ← C[1,2,1] = 221\n",
      "\n",
      "观察：第2维（最后一维）的元素保持在相同位置，只有前两维进行了交换\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"示例3：3D张量部分维度交换 perm=[1,0,2]\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 创建一个更直观的3D张量，每个元素包含其坐标信息\n",
    "C = tf.constant([[[100, 101], [110, 111], [120, 121]], \n",
    "                 [[200, 201], [210, 211], [220, 221]]])\n",
    "\n",
    "print(\"原始3D张量 C (shape: 2x3x2):\")\n",
    "print(\"可以理解为2个3x2的矩阵:\")\n",
    "for i in range(2):\n",
    "    print(f\"C[{i},:,:] =\")\n",
    "    print(C[i,:,:].numpy())\n",
    "\n",
    "# perm=[1,0,2] 意味着只交换第0和第1维，第2维保持不变\n",
    "C_t = tf.transpose(C, perm=[1, 0, 2])\n",
    "print(f\"\\n转置后 C_t (shape: 3x2x2):\")\n",
    "print(\"现在变成3个2x2的矩阵:\")\n",
    "for i in range(3):\n",
    "    print(f\"C_t[{i},:,:] =\")\n",
    "    print(C_t[i,:,:].numpy())\n",
    "\n",
    "print(\"\\n元素转换规则：C_t[i,j,k] = C[j,i,k] (因为perm=[1,0,2])\")\n",
    "print(\"详细转换过程:\")\n",
    "\n",
    "# 展示所有元素的转换\n",
    "for i in range(3):  # 新张量的第0维\n",
    "    for j in range(2):  # 新张量的第1维  \n",
    "        for k in range(2):  # 新张量的第2维\n",
    "            original_val = C[j, i, k].numpy()  # C_t[i,j,k] = C[j,i,k]\n",
    "            transposed_val = C_t[i, j, k].numpy()\n",
    "            print(f\"C_t[{i},{j},{k}] = {transposed_val:3d} ← C[{j},{i},{k}] = {original_val:3d}\")\n",
    "\n",
    "print(\"\\n观察：第2维（最后一维）的元素保持在相同位置，只有前两维进行了交换\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4702ddc",
   "metadata": {},
   "source": [
    "### 总结：tf.transpose 元素转换的核心规律\n",
    "\n",
    "1. **索引映射公式**：`y[i0, i1, ..., i_{n-1}] = x[i_{perm[0]}, i_{perm[1]}, ..., i_{perm[n-1]}]`\n",
    "\n",
    "2. **维度变换**：`y.shape[k] = x.shape[perm[k]]`\n",
    "\n",
    "3. **直观理解**：\n",
    "   - `perm[k]` 告诉我们新张量的第k维来自原张量的第`perm[k]`维\n",
    "   - 每个元素都会根据这个映射规则\"搬家\"到新位置\n",
    "\n",
    "4. **常见用法**：\n",
    "   - `perm=[1,0]`：2D矩阵的标准转置\n",
    "   - `perm=[2,1,0]`：完全反转所有维度\n",
    "   - `perm=[1,0,2]`：只交换前两维，保持其他维度不变\n",
    "\n",
    "下面运行一个交互式的验证工具："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd55344",
   "metadata": {},
   "source": [
    "##  Tenforflow concat \n",
    "\n",
    "Concatenates tensors along one dimension.  Concatenates the list of tensors values along dimension axis. if value[i].shape = [D0,D1,...,Daxis,...,Dn], the concatenated result has shape [D0,D1,...,Raxis,...,Dn], where Raxis = sum of Daxis over all tensors.\n",
    "\n",
    "This is, the data from the input tensors is joined along the axis dimension.\n",
    "the number of dimensions of the input tensors must match, and all dimensions except axis must be the same size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 2)\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  7  8]\n",
      " [ 4  5  6 10 11]], shape=(2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape)\n",
    "\n",
    "t2 = tf.constant([[7, 8], [10, 11]])\n",
    "print(t2.shape)\n",
    "\n",
    "result = tf.concat([t1, t2], axis=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c0f25",
   "metadata": {},
   "source": [
    "## TensorFlow 中 tensor softmax(x, axis=-1)\n",
    "\n",
    "Used for multi-class prediction. The sum of all outputs generated by softmax is 1.\n",
    "\n",
    "This function performs the equivalent of the following \n",
    "\n",
    "$$softmax = tf.exp(x) / tf.reduce\\_sum(tf.exp(x), axis=axis, keepdims=True)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03e10841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.09003057 0.24472848 0.66524094], shape=(3,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = tf.nn.softmax([-1, 0., 1.])\n",
    "print(softmax)\n",
    "\n",
    "sum(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057b192",
   "metadata": {},
   "source": [
    "####  TensorFlow 中 exponentation 函数 tf.exp(x)\n",
    "\n",
    "Computes the exponential of x element-wise. y = e^x\n",
    "\n",
    "This function computes the exponential of each element in the input tensor x. i.e. math.exp(x) or e^x. where x is the input tensor. \n",
    "e denotes Euler's number and is approximately equal to 2.718281828459045. Output is positive for any real input.  \n",
    "\n",
    "\n",
    "For complex(复数) numbers, the exponential function value is calculated as follows:\n",
    "$$ e^(a+bi) = e^a * (cos(b) + i*sin(b)) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b366f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.389056, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  2.7182817   7.389056   20.085537 ]\n",
      " [ 54.59815   148.41316   403.4288   ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2.0)\n",
    "print(tf.exp(x))\n",
    "\n",
    "x = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(tf.exp(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea71eb",
   "metadata": {},
   "source": [
    "####   TensorFlow math reduce_sum(input_tensor, axis=None, keepdims=False)\n",
    "\n",
    "Computes the sum of elements across dimensions of a tensor.\n",
    "\n",
    "This is the reduction operation for the elementwise tf.math.add op.\n",
    "\n",
    "reduces input_tensor along the dimensions given in axis. unless keepdims is true, the rank of the tensor is reduced by 1 for each entry in axis, which must be unique. if keepdims is true, the reduced dimensions are retained with length 1. For purpose of consistency of output shape, prefer to keepdims=True.\n",
    "\n",
    "if axis is None, all dimensions are reduced, and a tensor with a single element is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f7e2030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1]\n",
      " [1 1 1]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor([2 2 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3]\n",
      " [3]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# x has a shape of (2, 3) (two rows and three columns):\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "print(x)\n",
    "## sum all the elements \n",
    "print(tf.reduce_sum(x))\n",
    "\n",
    "## Reduce along the first dimension\n",
    "print(tf.reduce_sum(x, axis=0))  # shape (3,)\n",
    "\n",
    "## Reduce along the second dimension\n",
    "## keepdims = True 保持降维后的维度信息\n",
    "print(tf.reduce_sum(x, axis=1))  # shape (2,)\n",
    "\n",
    "## Reduce along the second dimension and keepdims=True\n",
    "print(tf.reduce_sum(x, axis=1, keepdims=True))  # shape (2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb498a",
   "metadata": {},
   "source": [
    "## TensorFlow中convert_to_tensor\n",
    "\n",
    "Converts the given value to a Tensor.\n",
    "\n",
    "This function converts python objects of various types to tensor objects. It accepts Tensor objects, numpy arrarys, python lists, python scalars and more.\n",
    "\n",
    "this function can be useful to when composing a new operation in python. All standard Python op constructors apply this function to each of their Tensor-valued inputs, which allows those ops to accept numpy arrarys, python lists, and scalars as inputs in addition to Tensor objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_func(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b4bb7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3],[4, 5, 6]], dtype=np.float32)\n",
    "print(x)\n",
    "\n",
    "value_1 = my_func(x)\n",
    "print(value_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5eb8cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow **IS NOT** using the GPU\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow **IS NOT** using the GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31c7437c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0283b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0992edb9",
   "metadata": {},
   "source": [
    "## TensorFlow Variables\n",
    "\n",
    "Normal tf.Tensor objects are immutable. To store model weights or other mutable state in TensorFlow use a  tf.Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ef2d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[5., 6.],\n",
      "       [7., 8.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[6., 7.],\n",
      "       [8., 9.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(var)\n",
    "\n",
    "var.assign([[5.0, 6.0], [7.0, 8.0]])\n",
    "print(var)\n",
    "\n",
    "var.assign_add([[1.0, 1.0], [1.0, 1.0]])\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045de3d",
   "metadata": {},
   "source": [
    "## Automatic differentiation（微分， 求导的过程，这个过程用于确定函数在某个点上瞬时的变换率或斜率）\n",
    "Gradient descent and related algorithms are a cornerstore (指的是建筑物底部或地基中放置的第一块石头， 通常有象征意义用来说明事物基础或者核心的部分) of modern machine learning . \n",
    "\n",
    "To enable this, Tenforflow implements automatic differentiation(autodiff), which uses calculus to compute gradients.  Typically, you'll use this to caluculate the gradient of a model's error or loss with respect to its weights. \n",
    "\n",
    "The simplified example only takes the derivative with respect to a single scalar variable x, but Tensorflow can compute the gradient with respect to any number of non-scalar tensors simultaneously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70d00be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)\n",
    "def f(x):\n",
    "    y = x**2 + 2*x - 5\n",
    "    return y\n",
    "\n",
    "f(x)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = f(x)\n",
    "\n",
    "g_x = tape.gradient(y, x) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81881552",
   "metadata": {},
   "source": [
    "### Introduction to gradients and automatic differentiation\n",
    "\n",
    "Automatic Differentiation is useful for implementing machine learning algorithms such as bacpropagation for training neural networks. \n",
    "\n",
    "In this guide, you will explore ways to compute gradients with Tensorflow, expecially in eager execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b4b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 22:00:14.659528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e6bb7",
   "metadata": {},
   "source": [
    "#### Computing gradients\n",
    "\n",
    "To differentiate automatically, Tensorflow needs to remember what operations happen in what order during the forward pass. Then, during the backward pass, Tensorflow traverses this list of operations in reverse order to compute the gradients.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab25c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282224a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90c956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590eee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad893ca0",
   "metadata": {},
   "source": [
    "## TensorFlow modules, layers, and models\n",
    "tf.Module is a class for managing your tf.Variables objects, and the tf.function objects that operate on them. \n",
    "The tf.Module class is necessary to support two significant features:\n",
    "\n",
    "1. You can save and restore the values of your variables using tf.train.Checkpoint. This is useful during training as it is quick to save and restore a model's state.\n",
    "2. You can import and export the tf.Variables value and the tf.function graphs using tf.saved_model. this is allows you to run your model independently of python pragram that created it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cee21",
   "metadata": {},
   "source": [
    "### TensorFlow Training loops\n",
    "\n",
    "Now put this all together to build a basic model and train it from scratch.\n",
    "\n",
    "First, create some example data. This generates a cloud of points that loosely follows a quadrtic curve. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b165c87",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
