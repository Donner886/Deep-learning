{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b08aae",
   "metadata": {},
   "source": [
    "## Tranfer Learning with MobileNetV2\n",
    "\n",
    "Welcome to the assignment, where you'll be using *transfer learning* on a pre-trained CNN to build an Alpaca/Not Alpaca classifier!\n",
    "\n",
    "A pre-trained model is a network that's already been trained on a large dataset and saved, which allows you to use it to customize your own model cheaply and efficiently. The one you'll be using, MobileNetV2, was designed to provide fast and computationally efficient performance. It's been pre-trained on ImageNet, a dataset containing over 14 million images and 1000 classes.\n",
    "\n",
    "By the end of this assignment, you'll be able to:\n",
    "- Create a dataset from a directory\n",
    "- Preprocess and augment data using the Sequential API\n",
    "- Adapt a pre-trained model to a new data and train a classifier using the Functional API and MobileNet\n",
    "- Fine-tune a classifier's final layers to improve accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda9eeb",
   "metadata": {},
   "source": [
    "### 1 - Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ef7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 09:14:51.994228: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccecb05",
   "metadata": {},
   "source": [
    "### 1.1 Create the Dataset and split it into Training and Validation Sets\n",
    "\n",
    "When training and evaluating a deep learning models in Keras, generating a dataset from image files stored on disk is simple and fast. Call the `image_dataset_from_directory` to read from the directory and create both training and validation datasets.\n",
    "\n",
    "If you are specifying a validation split, you'll also need to specify the `subset` argument. Just set the training set to `\"subset='training'\"` and the validation set to `\"subset='validation'\"`. \n",
    "\n",
    "You'll also set your seeds to match each other, so your training and validation sets don't overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.getcwd(), 'Chapter04-Convolutional-Neural-Networks',\n",
    "                       'DeepConvolutional_Models-CaseStudies', \n",
    "                       'W2A2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa514ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 327 files belonging to 2 classes.\n",
      "Using 262 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 09:49:44.053384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 327 files belonging to 2 classes.\n",
      "Using 65 files for validation.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "directory = 'dataset/'\n",
    "train_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset=\"training\",\n",
    "                                             seed=42,\n",
    "                                             batch_size = BATCH_SIZE,\n",
    "                                            image_size=IMG_SIZE)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(directory,\n",
    "                                                  shuffle=True,\n",
    "                                                  validation_split=0.2,\n",
    "                                                    subset=\"validation\",\n",
    "                                                    seed=42,\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200bb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
