from termcolor import colored
import tensorflow as tf
from tensorflow.python.framework.ops import EagerTensor
from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity
import numpy as np

def identity_block_test(target):
    tf.random.set_seed(2)
    np.random.seed(1)
    
    #X = np.random.randn(3, 4, 4, 6).astype(np.float32)
    X1 = np.ones((1, 4, 4, 3)) * -1
    X2 = np.ones((1, 4, 4, 3)) * 1
    X3 = np.ones((1, 4, 4, 3)) * 3

    X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)
    
    tf.keras.backend.set_learning_phase(False)
    
    A3 = target(X,
                f = 2,
                filters = [4, 4, 3],
                initializer=lambda seed=0:constant(value=1))


    A3np = A3.numpy()
    assert tuple(A3np.shape) == (3, 4, 4, 3), "Shapes does not match. This is really weird"
    assert np.all(A3np >= 0), "The ReLu activation at the last layer is missing"
    resume = A3np[:,(0,-1),:,:].mean(axis = 3)

    assert np.floor(resume[1, 0, 0]) == 2 * np.floor(resume[1, 0, 3]), "Check the padding and strides"
    assert np.floor(resume[1, 0, 3]) == np.floor(resume[1, 1, 0]),     "Check the padding and strides"
    assert np.floor(resume[1, 1, 0]) == 2 * np.floor(resume[1, 1, 3]), "Check the padding and strides"
    assert np.floor(resume[1, 1, 0]) == 2 * np.floor(resume[1, 1, 3]), "Check the padding and strides"

    assert resume[1, 1, 0] - np.floor(resume[1, 1, 0]) > 0.7, "Looks like the BatchNormalization units are not working"
    
    assert np.allclose(resume, 
                       np.array([[[  0.,        0.,        0.,        0.,     ],
                                  [  0.,        0.,       0.,        0.,     ]],
                                 [[192.99992, 192.99992, 192.99992,  96.99996],
                                  [ 96.99996,  96.99996,  96.99996,  48.99998]],
                                 [[578.99976, 578.99976, 578.99976, 290.99988],
                                  [290.99988, 290.99988, 290.99988, 146.99994]]]), 
                       atol = 1e-5 ), "Wrong values with training=False"

    tf.keras.backend.set_learning_phase(True)
    np.random.seed(1)
    tf.random.set_seed(2)
    A4 = target(X,
                f = 3,
                filters = [3, 3, 3],
                initializer=lambda seed=7:constant(value=1))
    A4np = A4.numpy()
    resume = A4np[:,(0,-1),:,:].mean(axis = 3)

    print('Public testing utils - Resume with training=True:')
    print(resume)
    assert np.allclose(resume, 
                             np.array([[[0.,         0.,         0.,         0.,        ],
                                  [0.,         0.,         0.,         0.,        ]],
                                 [[0.37387407, 0.37387407, 0.37387407, 0.37387407],
                                    [0.37387407, 0.37387407, 0.37387407, 0.37387407]],
                                [[3.2379277 , 4.1395493 , 4.1395493 , 3.2379277 ],
                                     [3.2379277 , 4.1395493 , 4.1395493 , 3.2379277 ]]]),
                          atol = 1e-5 ), "Wrong values with training=True"

    print(colored("All tests passed!", "green"))

    
def convolutional_block_test(target):
    np.random.seed(1)
    tf.random.set_seed(2)

    convolutional_block_output1 = [[[[0.,         0.77726924, 0.,         1.499777,   0.,         0.],
                                   [0.,         1.026826,   0.,         1.2753085,  0.,         0.]],
                                  [[0.,         1.0379409,  0.,         1.665507,   0.,         0.],
                                   [0.,         1.0401409,  0.,         1.3495028,  0.,         0.]]],
                                 [[[0.,         2.3318284,  0.,         4.4993644,  0.,         0.],
                                   [0.,         3.0805848,  0.,         3.8257396,  0.,         0.]],
                                  [[0.,         3.1137722,  0.,         4.9962516,  0.,         0.],
                                   [0.,         3.120653,   0.,         4.048527,   0.,         0.]]]]

    convolutional_block_output2 = np.array([[[[3.784147262573242, 0.0, 0.0, 0.28541332483291626, 0.0, 0.0],
      [1.808715581893921, 0.968281626701355, 0.0, 1.5040215253829956, 0.0, 0.0]],
      [[1.2142595052719116, 1.7465354204177856, 0.0, 1.9497969150543213, 0.0, 0.0],
      [1.50904381275177, 1.8908942937850952, 0.0, 1.86744225025177, 0.0, 0.0]]],
      [[[0.0,
        0.37060117721557617,
        0.7255364656448364,
        0.7189911007881165,
        0.15137478709220886,
        0.5512183904647827],
      [0.0,
        0.37060120701789856,
        0.7255364656448364,
        0.7189909815788269,
        0.15137480199337006,
        0.5512184500694275]], [[0.0,
        0.370601087808609,
        0.7255364656448364,
        0.7189911007881165,
        0.1513747125864029,
        0.5512182116508484],
      [0.0,
        0.3706011474132538,
        0.7255364656448364,
        0.7189911007881165,
        0.15137475728988647,
        0.5512182712554932]]], [[[0.0, 0.0, 0.0, 0.0, 2.6875762939453125, 0.0],
      [0.0,
        0.0,
        1.8783891201019287,
        0.0,
        1.0258095264434814,
        0.5061106085777283]], [[0.0,
        0.0,
        0.008338093757629395,
        0.0,
        0.3775590658187866,
        0.9526755213737488], [0.0,
        0.014011025428771973,
        0.9290347099304199,
        0.0,
        2.211538076400757,
        1.7997167110443115]]]]
      )   
    #X = np.random.randn(3, 4, 4, 6).astype(np.float32)
    X1 = np.ones((1, 4, 4, 3)) * -1
    X2 = np.ones((1, 4, 4, 3)) * 1
    X3 = np.ones((1, 4, 4, 3)) * 3

    X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)

    print('Public testing utils - Convolutional Block:')
    print(f'The original X shape is {X.shape}')
    tf.keras.backend.set_learning_phase(False)
    
    A = target(X, f = 2, s = 4, filters = [2, 4, 6])
    assert tuple(tf.shape(A).numpy()) == (3, 1, 1, 6), "Wrong shape. Make sure you are using the stride values as expected."
    
    B = target(X, f = 2, filters = [2, 4, 6])
    assert type(B) == EagerTensor, "Use only tensorflow and keras functions"
    assert tuple(tf.shape(B).numpy()) == (3, 2, 2, 6), "Wrong shape."
    #assert np.allclose(A.numpy(), convolutional_block_output1), "Wrong values when training=False."
    print(B[0]) 
    
    tf.keras.backend.set_learning_phase(True)
    
    C = target(X, f = 2, filters = [2, 4, 6])
    assert np.allclose(C.numpy(), convolutional_block_output2), "Wrong values when training=True."

    print('\033[92mAll tests passed!')